{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys as _sys\n",
    "import os\n",
    "\n",
    "currentPath = os.path.abspath(os.getcwd())\n",
    "\n",
    "split = currentPath.split(\"Cshells\")\n",
    "if len(split)<2:\n",
    "    print(\"Please rename the repository 'Cshells'\")\n",
    "    raise ValueError\n",
    "pathToPythonScripts = split[0] + \"Cshells/python/\"\n",
    "pathToModels = os.path.join(split[0], \"Cshells/data/models\")\n",
    "pathToOutputs = os.path.join(split[0], \"Cshells/output\")\n",
    "\n",
    "_sys.path.insert(0, pathToPythonScripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeshFEM\n",
    "import ElasticRods\n",
    "\n",
    "import average_angle_linkages\n",
    "from bending_validation import suppress_stdout as so\n",
    "import elastic_rods\n",
    "import math\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "from CShell import CShell\n",
    "from CurvesDoFOptimizer import CurvesDoFOptimizer\n",
    "from linkage_vis import LinkageViewer\n",
    "from open_average_angle_linkage import ComputeStressesHistogram, open_average_angle_linkage, RunAndAnalyzeDeployment, PlotDeploymentQuantities\n",
    "import py_newton_optimizer\n",
    "from vis.fields import ScalarField\n",
    "from VisUtils import ConvergencePlotsVisualizer, PlotStackedConvergencePlots\n",
    "from VisUtilsDeployment import CompareDeploymentStatistics, CompareDeploymentQuantities\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "    \n",
    "def ToNumpy(tensor):\n",
    "    return tensor.cpu().detach().clone().numpy()\n",
    "\n",
    "PI = math.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"torus_symmetric\"\n",
    "\n",
    "with open(os.path.join(pathToModels, modelName, \"flat_optimized.p\"), 'rb') as f:\n",
    "    flatLinkage = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(pathToModels, modelName, \"deployed_optimized.p\"), 'rb') as f:\n",
    "    depLinkage = pickle.load(f)\n",
    "    \n",
    "linkagesGuess = {\n",
    "    \"flat\": flatLinkage,\n",
    "    \"deployed\": depLinkage,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(pathToModels, modelName, \"cshell_optimized.p\"), 'rb') as f:\n",
    "    dictCShell = pickle.load(f)\n",
    "    \n",
    "cshell = CShell(\n",
    "    dictCShell[\"curvesDoF\"], dictCShell[\"nJ\"], dictCShell[\"curves\"], dictCShell[\"curvesFamily\"], dictCShell[\"nCPperRodEdge\"], \n",
    "    dictCShell[\"alphaTar\"].item(), dictCShell[\"mult\"], dictCShell[\"subdivision\"], symmetry=dictCShell[\"symmetry\"],\n",
    "    attractionMesh=dictCShell[\"attractionMesh\"], targetMesh=dictCShell[\"targetMesh\"],\n",
    "    rodMaterial=dictCShell[\"flatLinkage\"].homogenousMaterial(), optimizeAlpha=True, useSAL=True, \n",
    "    linkagesGuess=linkagesGuess, flatOnly=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cshell.flatView.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cshell.deployedView.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different actuations\n",
    "\n",
    "We show different actuation strategies for the same model and record some metric along the deployment paths. Note that `RunAndAnalyzeDeployment` creates a copy linkage and hence does not modify the input linkage. More details about how to recover the deployed linkage can be found in `python/open_average_angle_linkage.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeActuations = True\n",
    "numOpeningSteps = 30\n",
    "maxNewtonIterIntermediate = 500 # maximum number of equilibrium steps taken per opening step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment using the flat state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatLinkDep = average_angle_linkages.AverageAngleLinkage(cshell.flatLinkage)\n",
    "targetLinkDep = average_angle_linkages.AverageAngleLinkage(cshell.deployedLinkage)\n",
    "\n",
    "viewerDep = LinkageViewer(flatLinkDep, width=768, height=480)\n",
    "viewerDep.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if computeActuations:\n",
    "    initDeployment = RunAndAnalyzeDeployment(\n",
    "        flatLinkDep, targetLinkDep, numOpeningSteps=numOpeningSteps,\n",
    "        maxNewtonIterIntermediate=maxNewtonIterIntermediate, view=viewerDep\n",
    "    )\n",
    "    initStressHist = ComputeStressesHistogram(initDeployment[\"stresses\"])\n",
    "    PlotDeploymentQuantities(initDeployment, initStressHist)\n",
    "    successes = [initDeployment['ConvergenceReports'][i].success for i in range(len(initDeployment['ConvergenceReports']))]\n",
    "    gradNorms = [initDeployment['ConvergenceReports'][i].gradientNorm[-1] for i in range(len(initDeployment['ConvergenceReports']))]\n",
    "    freeGradNorms = [initDeployment['ConvergenceReports'][i].freeGradientNorm[-1] for i in range(len(initDeployment['ConvergenceReports']))]\n",
    "    print(\"Convergence success percentage {:.2f}%\".format(100.0*np.mean(successes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undeployment from the deployed state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatLinkUndep = average_angle_linkages.AverageAngleLinkage(cshell.flatLinkage)\n",
    "targetLinkUndep = average_angle_linkages.AverageAngleLinkage(cshell.deployedLinkage)\n",
    "\n",
    "viewerUndep = LinkageViewer(targetLinkUndep, width=768, height=480)\n",
    "viewerUndep.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if computeActuations:\n",
    "    unDeployment = RunAndAnalyzeDeployment(\n",
    "        targetLinkUndep, flatLinkUndep, numOpeningSteps=numOpeningSteps,\n",
    "        maxNewtonIterIntermediate=maxNewtonIterIntermediate, view=viewerUndep\n",
    "    )\n",
    "    undepStressHist = ComputeStressesHistogram(unDeployment[\"stresses\"])\n",
    "    PlotDeploymentQuantities(unDeployment, undepStressHist)\n",
    "    undepSuccesses = [unDeployment['ConvergenceReports'][i].success for i in range(len(unDeployment['ConvergenceReports']))]\n",
    "    undepGradNorms = [unDeployment['ConvergenceReports'][i].gradientNorm[-1] for i in range(len(unDeployment['ConvergenceReports']))]\n",
    "    undepFreeGradNorms = [unDeployment['ConvergenceReports'][i].freeGradientNorm[-1] for i in range(len(unDeployment['ConvergenceReports']))]\n",
    "    print(\"Convergence success percentage {:.2f}%\".format(100.0*np.mean(undepSuccesses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table trick\n",
    "\n",
    "To deploy our physical prototype into the intended shape, we used a table to constrain some joints. Hence the name table trick. In the code, we simply pin the z coordinate of valence 2 joints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedHeights = []\n",
    "for ji in range(cshell.nJ):\n",
    "    if cshell.deployedLinkage.joint(ji).valence() == 2:\n",
    "        fixedHeights.append(cshell.deployedLinkage.dofOffsetForJoint(ji) + 2)\n",
    "\n",
    "flatLinkTT = average_angle_linkages.AverageAngleLinkage(cshell.flatLinkage)\n",
    "targetLinkTT = average_angle_linkages.AverageAngleLinkage(cshell.deployedLinkage)\n",
    "\n",
    "viewerTT = LinkageViewer(flatLinkTT, width=768, height=480)\n",
    "viewerTT.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if computeActuations:\n",
    "    tableTrick = RunAndAnalyzeDeployment(\n",
    "        flatLinkTT, targetLinkTT, numOpeningSteps=numOpeningSteps, \n",
    "        maxNewtonIterIntermediate=maxNewtonIterIntermediate,\n",
    "        additionalFixedVars=fixedHeights, releaseFixedVarsAngle=1.45,\n",
    "        view=viewerTT,\n",
    "    )\n",
    "    ttStressHist = ComputeStressesHistogram(tableTrick[\"stresses\"])\n",
    "    PlotDeploymentQuantities(tableTrick, ttStressHist)\n",
    "    ttSuccesses = [tableTrick['ConvergenceReports'][i].success for i in range(len(tableTrick['ConvergenceReports']))]\n",
    "    ttGradNorms = [tableTrick['ConvergenceReports'][i].gradientNorm[-1] for i in range(len(tableTrick['ConvergenceReports']))]\n",
    "    ttFreeGradNorms = [tableTrick['ConvergenceReports'][i].freeGradientNorm[-1] for i in range(len(tableTrick['ConvergenceReports']))]\n",
    "    print(\"Convergence success percentage {:.2f}%\".format(100.0*np.mean(ttSuccesses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saddle deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatLinkSaddle = average_angle_linkages.AverageAngleLinkage(cshell.flatLinkage)\n",
    "targetLinkSaddle = average_angle_linkages.AverageAngleLinkage(cshell.flatLinkage)\n",
    "\n",
    "def equilibriumSolver(tgtAngle, l, opts, fv):\n",
    "    opts.gradTol = 1.0e-5\n",
    "    return average_angle_linkages.compute_equilibrium(l, tgtAngle, options=opts, fixedVars=fv)\n",
    "\n",
    "numOpeningSteps = 10\n",
    "maxNewtonIterIntermediate = 500\n",
    "driver = targetLinkSaddle.centralJoint()\n",
    "\n",
    "with so(): open_average_angle_linkage(\n",
    "    targetLinkSaddle, driver, -0.20, 10, \n",
    "    None, equilibriumSolver=equilibriumSolver, \n",
    "    maxNewtonIterationsIntermediate=500\n",
    ")\n",
    "\n",
    "viewerSaddle = LinkageViewer(flatLinkSaddle, width=768, height=480)\n",
    "viewerSaddle.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if computeActuations:\n",
    "    saddleDeployment = RunAndAnalyzeDeployment(\n",
    "        flatLinkSaddle, targetLinkSaddle, numOpeningSteps=numOpeningSteps, \n",
    "        maxNewtonIterIntermediate=maxNewtonIterIntermediate, view=viewerSaddle,\n",
    "    )\n",
    "    \n",
    "    toSaddleStressHist    = ComputeStressesHistogram(saddleDeployment[\"stresses\"])\n",
    "    PlotDeploymentQuantities(saddleDeployment, toSaddleStressHist)\n",
    "    toSaddleSuccesses     = [saddleDeployment['ConvergenceReports'][i].success for i in range(len(saddleDeployment['ConvergenceReports']))]\n",
    "    toSaddleGradNorms     = [saddleDeployment['ConvergenceReports'][i].gradientNorm[-1] for i in range(len(saddleDeployment['ConvergenceReports']))]\n",
    "    toSaddleFreeGradNorms = [saddleDeployment['ConvergenceReports'][i].freeGradientNorm[-1] for i in range(len(saddleDeployment['ConvergenceReports']))]\n",
    "    print(\"Convergence success percentage {:.2f}%\".format(100.0*np.mean(toSaddleSuccesses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToSave = os.path.join(pathToOutputs, \"torus_symmetric/deployment\")\n",
    "if not os.path.exists(pathToSave):\n",
    "    os.makedirs(pathToSave)\n",
    "\n",
    "if computeActuations:\n",
    "    with open(os.path.join(pathToSave, \"deploymentCShellOptim.p\"), 'wb') as f:\n",
    "        pickle.dump({key: initDeployment[key] for key in initDeployment if key!=\"ConvergenceReports\"}, f)\n",
    "\n",
    "    with open(os.path.join(pathToSave, \"unDeploymentCShellOptim.p\"), 'wb') as f:\n",
    "        pickle.dump({key: unDeployment[key] for key in unDeployment if key!=\"ConvergenceReports\"}, f)\n",
    "    \n",
    "    with open(os.path.join(pathToSave, \"tableTrickCShellOptim.p\"), 'wb') as f:\n",
    "        pickle.dump({key: tableTrick[key] for key in tableTrick if key!=\"ConvergenceReports\"}, f)\n",
    "    \n",
    "    with open(os.path.join(pathToSave, \"toSaddleCShellOptim.p\"), 'wb') as f:\n",
    "        pickle.dump({key: saddleDeployment[key] for key in saddleDeployment if key!=\"ConvergenceReports\"}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualize deployments\n",
    "\n",
    "We may not want to recompute the deployments every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listPathsHists = [\n",
    "    os.path.join(pathToSave, \"deploymentCShellOptim.p\"),\n",
    "    os.path.join(pathToSave, \"unDeploymentCShellOptim.p\"),\n",
    "    os.path.join(pathToSave, \"tableTrickCShellOptim.p\"),\n",
    "    os.path.join(pathToSave, \"toSaddleCShellOptim.p\")\n",
    "]\n",
    "\n",
    "listNames = [\"Deployment\", \"Undeployment\", \"Table Trick\", \"To Saddle\"]\n",
    "\n",
    "listDeployments = []\n",
    "\n",
    "for path in listPathsHists:\n",
    "    with open(path, 'rb') as f:\n",
    "        deployment = pickle.load(f)\n",
    "    \n",
    "    listDeployments.append(deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listShow = [False, True]\n",
    "\n",
    "listFnStresses = [\n",
    "    os.path.join(pathToSave, \"stresses.png\"),\n",
    "    os.path.join(pathToSave, \"stressesNoText.png\"),\n",
    "]\n",
    "\n",
    "for show, fn in zip(listShow, listFnStresses):\n",
    "    CompareDeploymentStatistics(\n",
    "        listDeployments, listNames=listNames, xlim=None, \n",
    "        minBounds=None, maxBounds=None, useMedian=True,\n",
    "        filename=fn, showText=show, vmOnly=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listShow = [False, True]\n",
    "\n",
    "listFnEnergies = [\n",
    "    os.path.join(pathToSave, \"energiesDep.png\"),\n",
    "    os.path.join(pathToSave, \"energiesDepNoText.png\"),\n",
    "]\n",
    "\n",
    "for show, fn in zip(listShow, listFnEnergies):\n",
    "    CompareDeploymentQuantities(\n",
    "        listDeployments, listNames=listNames, xlimEnergies=None, ylimEnergies=None, \n",
    "        xlimTorque=None, ylimTorque=None, \n",
    "        showTorque=False, showAnnotations=False, showText=show, filename=fn\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "532253dd1d492a531a4a0e9f5a112e3e98e55d99579588313b14d9cd640c91ba"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
